{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import io\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from numcodecs import GZip, Zstd, Blosc\n",
    "\n",
    "from albk.data.utils import get_google_maps_static_image\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapefile is downloaded from: \n",
    "\n",
    "| Country/City | Link |\n",
    "| --- | --- |\n",
    "| Bangladesh | https://www.kaggle.com/datasets/tsgreen/bangladesh-administrative-boundaries-shapefiles/data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = 'bangladesh'\n",
    "gdf = gpd.read_file(f'shapefiles/{geometry}/bgd_admbnda_adm0_bbs_20180410.shp')\n",
    "gdf.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create index of points to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unary_shape = gdf.unary_union\n",
    "min_lon, min_lat, max_lon, max_lat = unary_shape.bounds\n",
    "print(min_lon, min_lat, max_lon, max_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following gap has some overlap but it is choosen to have multiples of 0.01\n",
    "lat_gap = 0.01\n",
    "lon_gap = 0.01\n",
    "lats = np.arange(np.round(min_lat, 2)-lat_gap, np.round(max_lat, 2)+lat_gap*2, lat_gap)\n",
    "lons = np.arange(np.round(min_lon, 2)-lon_gap, np.round(max_lon, 2)+lon_gap*2, lon_gap)\n",
    "print(len(lats), len(lons), len(lats)*len(lons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lat, Lon = np.meshgrid(lats, lons)\n",
    "latlon_pairs = np.vstack([Lat.ravel(), Lon.ravel()]).T\n",
    "print(latlon_pairs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we discard the points that are not in a Geometry. We will use the `shapely` library to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_gdf = gpd.GeoDataFrame(geometry=[Point(y, x) for x, y in latlon_pairs])\n",
    "def check_within(gdf_chunk):\n",
    "    return gdf_chunk.within(unary_shape).values\n",
    "\n",
    "chunk_size = 100\n",
    "chunks = [point_gdf[i:i+chunk_size] for i in range(0, len(point_gdf), chunk_size)]\n",
    "results = Parallel(n_jobs=48)(delayed(check_within)(chunk) for chunk in tqdm(chunks))\n",
    "latlon_bool = np.concatenate(results)\n",
    "print(len(latlon_bool), latlon_bool.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon_pairs_in_geometry = latlon_pairs[latlon_bool]\n",
    "\n",
    "def convert_to_string(latlon_pair):\n",
    "    lat, lon = latlon_pair\n",
    "    return f'{lat:.2f},{lon:.2f}'\n",
    "\n",
    "latlon_pairs_in_geometry = [convert_to_string(latlon_pair) for latlon_pair in latlon_pairs_in_geometry]\n",
    "\n",
    "print(latlon_pairs_in_geometry[:3])\n",
    "print(len(latlon_pairs_in_geometry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to download a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lag = np.array([-2, -1, 0, 1, 2], dtype=np.int8)\n",
    "lon_lag = np.array([-2, -1, 0, 1, 2], dtype=np.int8)\n",
    "rows = np.array(np.arange(224), dtype=np.uint8)\n",
    "cols = np.array(np.arange(224), dtype=np.uint8)\n",
    "channels = np.array([0, 1, 2], dtype=np.uint8)\n",
    "labels = (np.zeros((5, 5)) - 1).astype(np.int8)\n",
    "path = os.path.join(os.path.expanduser(\"~\"), 'bkdb', geometry)\n",
    "key = os.getenv('SMTGML_GMS') # DHRUV_GMS, ZEEL_IITGN_GMS, SURAJ_GMS, ZEEL_GMS, ANONY_GMS, VISHESH_GMS, SMTGML_GMS\n",
    "\n",
    "def download_it(lat_lon):\n",
    "    # Download image\n",
    "    img_bytes = get_google_maps_static_image(key, lat_lon, zoom=16, size=(640, 640), scale=2)\n",
    "    img_io = io.BytesIO(img_bytes)\n",
    "    img = plt.imread(img_io)\n",
    "    \n",
    "    # Center crop to allow 5x5 patches of size 224x224x3 from 1120x1120x3\n",
    "    cut_img = img[80:-80, 80:-80, :3]\n",
    "    assert cut_img.shape == (224*5, 224*5, 3), f\"cut_img.shape = {cut_img.shape}\"\n",
    "    \n",
    "    # Split into 5x5 patches: (5, 5, 224, 224, 3)\n",
    "    data = np.array([np.split(tmp_img, 5, axis=1) for tmp_img in np.split(cut_img, 5, axis=0)])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    \n",
    "    save_path = os.path.join(path, f\"{lat_lon}.zarr\")\n",
    "    lat, lon = lat_lon.split(',')\n",
    "    lat, lon = float(lat), float(lon)\n",
    "    ds = xr.Dataset(\n",
    "    {\n",
    "        'data': (['lat_lag', 'lon_lag', 'row', 'col', 'channel'], data),\n",
    "        'label': (['lat_lag', 'lon_lag'], labels),\n",
    "    },\n",
    "    coords={\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'row': rows,\n",
    "        'col': cols,\n",
    "        'channel': channels,\n",
    "        'lat_lag': lat_lag,\n",
    "        'lon_lag': lon_lag,\n",
    "    },\n",
    "    )\n",
    "    encoding = {'data': {'compressor': GZip(level=9)}}\n",
    "    ds.to_zarr(save_path, consolidated=False, encoding=encoding, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test download\n",
    "# download_it(latlon_pairs_in_geometry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got these pairs after finding closest pairs to predicted brick kilns\n",
    "#any special pairs to download\n",
    "special_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_folders = os.listdir(path)\n",
    "def check_if_exists(folder):\n",
    "    try:\n",
    "        ds = xr.open_zarr(os.path.join(path, folder), consolidated=False)\n",
    "        assert ds.data.shape == (5, 5, 224, 224, 3)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        return False\n",
    "\n",
    "does_exists = Parallel(n_jobs=48)(delayed(check_if_exists)(folder) for folder in tqdm(existing_folders))\n",
    "existing_pairs = [folder.replace(\".zarr\", \"\") for folder, exists in zip(existing_folders, does_exists) if exists]\n",
    "\n",
    "to_download_pairs = sorted(set(latlon_pairs_in_geometry+special_pairs) - set(existing_pairs))\n",
    "print(len(latlon_pairs_in_geometry+special_pairs), \"in\", geometry)\n",
    "print(len(existing_pairs), \"already downloaded\")\n",
    "print(len(to_download_pairs), \"to download\")\n",
    "\n",
    "_ = Parallel(n_jobs=48)(delayed(download_it)(lat_lon) for lat_lon in tqdm(to_download_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| File Format                                   | Disk Space Consumption            | Time Taken               |\n",
    "|-----------------------------------------------|-----------------------------------|--------------------------|\n",
    "| `png` (200 points, 5000 images)               | 461 MB                            | 8.4 seconds              |\n",
    "| `npy` (200 points, 5000 images)               | 725 MB                            | 6.4 seconds              |\n",
    "| `npz` (200 points, 5000 images)               | 241 MB                            | 7.5 seconds              |\n",
    "| `h5` (gzip compression, 200 points, 5000 images)| 423 MB                           | 6.7 seconds              |\n",
    "| `zarr` (Zstd compression, 200 points, 5000 images)| 364 MB                         | 7.0 seconds              |\n",
    "| `zarr` (Gzip(level=1) compression, 200 points, 5000 images)| 299 MB                    | 8.1 seconds              |\n",
    "| `zarr` (Gzip(level=9) compression, 200 points, 5000 images)| 261 MB                    | 8.7 seconds              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     img = np.load(os.path.join(path, \"21.03,92.25\", f\"{i}_0.npz\"))['arr_0']\n",
    "#     plt.figure()\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "#     label = int(input(\"Enter label: \"))\n",
    "#     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(os.path.join(path, \"*.zarr\"))\n",
    "ds = xr.open_zarr(files[0], consolidated=False)\n",
    "ds.sel(lat_lag=0, lon_lag=0)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds.sel(lat_lag=0, lon_lag=0)['data'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
