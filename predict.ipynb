{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from shapely.geometry import Polygon, Point\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.models import efficientnet_b0\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = \"/home/vannsh.jani/brick_kilns/githubrepo/ML/model_50_no_ssl_features_imagenet.pth\"\n",
    "c_path = \"/home/vannsh.jani/brick_kilns/githubrepo/ML/model_50_no_ssl_classifier_imagenet.pth\"\n",
    "\n",
    "model = efficientnet_b0(pretrained=False)\n",
    "model.classifier = nn.Linear(1280,2)\n",
    "model.features.load_state_dict(torch.load(f_path))\n",
    "model.classifier.load_state_dict(torch.load(c_path))\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"/home/rishabh.mondal/Brick-Kilns-project/albk/experiments/data_preperation/shapefiles/statewise/DISTRICT_BOUNDARY.shp\")\n",
    "gdf.columns\n",
    "gdf['District'] = gdf['District'].str.replace('>', 'A')\n",
    "gdf['District'] = gdf['District'].str.replace('<', 'A')\n",
    "gdf['STATE'] = gdf['STATE'].str.replace('>', 'A') \n",
    "gdf['STATE'] = gdf['STATE'].str.replace('<', 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_gdf = gdf[gdf['STATE'] == 'BIHAR']\n",
    "state_gdf = gdf[gdf['STATE'] == 'UTTAR PRADESH']\n",
    "# delhi_gdf = gdf[gdf['STATE'] == 'PUNJAB']\n",
    "state_gdf.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district = \"AZAMGARH\".upper()\n",
    "custom_gdf = gdf[gdf[\"District\"] == district]\n",
    "state_gdf = state_gdf.to_crs(epsg=4326)\n",
    "custom_gdf = custom_gdf.to_crs(epsg=4326)\n",
    "\n",
    "custom_gdf.plot()\n",
    "# state_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_gdf=state_gdf\n",
    "## All pairs within the district\n",
    "lon_min, lat_min, lon_max, lat_max = custom_gdf.geometry.unary_union.bounds\n",
    "\n",
    "union = custom_gdf.geometry.unary_union\n",
    "# print(union)\n",
    "pairs = []\n",
    "for lat in tqdm(np.arange(lat_min-0.02, lat_max+0.02, 0.01),desc=\"Latitude progress\"):\n",
    "    for lon in (np.arange(lon_min-0.02, lon_max+0.02, 0.01)):\n",
    "        # check if the point is within the district\n",
    "        point = Point(lon, lat)\n",
    "        if union.contains(point):\n",
    "            pairs.append((lon, lat))\n",
    "            \n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process pairs\n",
    "proessed_pairs = []\n",
    "for pair in pairs:\n",
    "    # format to .2f\n",
    "    lon, lat = pair\n",
    "    \n",
    "    lon = f\"{round(lon, 2):.2f}\"\n",
    "    lat = f\"{round(lat, 2):.2f}\"\n",
    "    proessed_pairs.append(f\"{lat},{lon}.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proessed_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(\"/home/jaiswalsuraj/bkdb/india/bihar/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"/home/jaiswalsuraj/bkdb/india/\")\n",
    "# os.listdir(\"/home/rishabh.mondal/bkdb/statewise/up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"/home/jaiswalsuraj/bkdb/india/haryana/\"\n",
    "# data_path = \"/home/jaiswalsuraj/bkdb/india/bihar/\"\n",
    "data_path = '/home/rishabh.mondal/bkdb/statewise/up'\n",
    "available_files = []\n",
    "non_available_files = []\n",
    "for pair in tqdm(proessed_pairs):\n",
    "    if os.path.exists(join(data_path, pair)):\n",
    "        available_files.append(join(data_path, pair))\n",
    "    else:\n",
    "        non_available_files.append(join(data_path, pair))\n",
    "print(f\"Available: {len(available_files)}\")\n",
    "print(f\"Non-Available: {len(non_available_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(available_files[1391])\n",
    "xr.open_zarr(available_files[1391], consolidated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "idx_list = []\n",
    "\n",
    "def process_file(file):\n",
    "    try:\n",
    "        data = xr.open_zarr(file, consolidated=False)\n",
    "        img_list = []\n",
    "        idx_list = []\n",
    "        for lat_lag in range(-2, 3):\n",
    "            for lon_lag in range(-2, 3):\n",
    "                img = data[\"data\"].sel(lat_lag=lat_lag, lon_lag=lon_lag).values\n",
    "                lat = data[\"lat\"].values.item()\n",
    "                lon = data[\"lon\"].values.item()\n",
    "                idx = f\"{lat:.2f},{lon:.2f}_{lat_lag}_{lon_lag}\"\n",
    "                img = torch.tensor(img) / 255.0\n",
    "                img = torch.einsum(\"hwc -> chw\", img)\n",
    "                img_list.append(img)\n",
    "                idx_list.append(idx)\n",
    "        return torch.stack(img_list), idx_list\n",
    "    except KeyError as e:\n",
    "        print(f\"Skipping file {file} due to KeyError: {e}\")\n",
    "        return None\n",
    "\n",
    "# Your list of files\n",
    "# available_files = [...]\n",
    "\n",
    "# Parallel processing with error handling\n",
    "results = Parallel(n_jobs=48)(delayed(process_file)(file) for file in tqdm(available_files) if process_file(file) is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = torch.cat([result[0] for result in results], dim=0)\n",
    "mean = all_images.mean(dim=(0, 2, 3), keepdims=True)\n",
    "std = all_images.std(dim=(0, 2, 3), keepdims=True)\n",
    "all_images = (all_images - mean) / std\n",
    "all_idx = [idx for result in results for idx in result[1]]\n",
    "print(all_images.shape, len(all_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "all_preds = []\n",
    "\n",
    "for i in tqdm(range(0, len(all_images), batch_size)):\n",
    "    batch = all_images[i:i+batch_size].to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(batch).argmax(dim=1).cpu()\n",
    "    all_preds.append(preds)\n",
    "\n",
    "all_preds = torch.cat(all_preds, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_positive_idx = (all_preds == 1)\n",
    "print(pred_positive_idx.sum())\n",
    "\n",
    "locs = np.array(all_idx)[pred_positive_idx]\n",
    "# print(locs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_positive_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name, lags = locs[3].split(\"_\", 1)\n",
    "lat_lag, lon_lag = lags.split(\"_\")\n",
    "plt.imshow(xr.open_zarr(join(data_path, file_name+\".zarr\"), consolidated=False).sel(lat_lag=int(lat_lag), lon_lag=int(lon_lag))['data'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import img_as_ubyte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_images)\n",
    "len(all_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaled_images = (all_images * std) + mean\n",
    "all_images_numpy = rescaled_images.cpu().numpy()\n",
    "\n",
    "save_path = \"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/predicted_positive/UTTAR_Pradesh/AZAMGARH/\"\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for i, img in tqdm(enumerate(all_images_numpy[pred_positive_idx])):\n",
    "    img_normalized = img / img.max()\n",
    "    img = img_as_ubyte(img_normalized)\n",
    "    plt.imsave(join(save_path, f\"{locs[i]}.png\"), np.moveaxis(img, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/predicted_positive/UTTAR_Pradesh/lucknow\"\n",
    "\n",
    "files = os.listdir(path)\n",
    "file_names = []\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(path, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        file_names.append(file)\n",
    "\n",
    "print(file_names)\n",
    "file_list=[file.split('_')[:-2] for file in file_names]\n",
    "print(file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your list of coordinates\n",
    "coordinates = file_list\n",
    "# Extracting latitude and longitude from the coordinates list\n",
    "points = [(float(coord[0].split(',')[0]), float(coord[0].split(',')[1])) for coord in coordinates]\n",
    "print(points)\n",
    "# Create a GeoDataFrame for the points\n",
    "points_gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy([point[1] for point in points], [point[0] for point in points]))\n",
    "print(points_gdf)\n",
    "# Plotting the custom_gdf\n",
    "ax = custom_gdf.plot(color='lightblue', edgecolor='black', figsize=(8, 8))\n",
    "\n",
    "# Plotting the points on the same plot\n",
    "points_gdf.plot(ax=ax, color='red', marker='o',label='Brick Kilns')\n",
    "ax.text(80.95, 26.82, 'Lucknow', color='black', fontsize=13, ha='center')\n",
    "plt.legend()\n",
    "plt.title('Brick Kilns in Lucknow')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
